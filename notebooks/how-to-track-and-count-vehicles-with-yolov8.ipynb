{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shlFfLEcQea1"
      },
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# YOLOv8 Tracking and Counting\n",
        "\n",
        "---\n",
        "\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/OS5qI9YBkfk)\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/yolov8-tracking-and-counting/)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "## ⚠️ Disclaimer\n",
        "\n",
        "This notebook uses legacy versions of ByteTrack and Supervision. To be up to date, use our updated [notebook](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-track-and-count-vehicles-with-yolov8-and-supervison.ipynb).\n",
        "\n",
        "## Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the [blog post](https://blog.roboflow.com/yolov8-tracking-and-counting/) on how to train YOLOv8 Tracking and Counting, concurrently.\n",
        "\n",
        "## Pro Tip: Use GPU Acceleration\n",
        "\n",
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
        "\n",
        "## Steps in this Tutorial\n",
        "\n",
        "In this tutorial, we are going to cover:\n",
        "\n",
        "- Before you start\n",
        "- Download video\n",
        "- Install YOLOv8\n",
        "- Install ByteTrack\n",
        "- Install Roboflow Supervision\n",
        "- Tracking utils\n",
        "- Load pre-trained YOLOv8 model\n",
        "- Predict and annotate single frame\n",
        "- Predict and annotate whole video\n",
        "\n",
        "**Let's begin!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCVyYjLXofL9"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4okzdHlKMaj",
        "outputId": "e86edf1f-0abd-4228-8330-572fcdcf453d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 28 01:32:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "984J4pv4K2D-",
        "outputId": "5a882a21-66e5-41c1-a0e2-6f10e63780f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Zyej4SSZNE"
      },
      "source": [
        "## Download video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ctvdpAiRSb1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67495bf-0584-4bb6-a0e3-9b238e0db66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2025-03-28 01:50:47--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.137.101, 74.125.137.113, 74.125.137.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.137.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download [following]\n",
            "--2025-03-28 01:50:47--  https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.137.132, 2607:f8b0:4023:c03::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.137.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: ‘vehicle-counting.mp4’\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M  90.6MB/s    in 0.4s    \n",
            "\n",
            "2025-03-28 01:50:49 (90.6 MB/s) - ‘vehicle-counting.mp4’ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gtxQLn33TBWo"
      },
      "outputs": [],
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/vehicle-counting.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install supervision==0.1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTi5K4t8a5Rj",
        "outputId": "9a54b69b-2bfe-40dc-feb4-38bb1293dfb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supervision==0.1.0 in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from supervision==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from supervision==0.1.0) (4.11.0.86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "_RAuDNxNdRdA",
        "outputId": "3cf23854-b4ae-4f51-c714-134670acf6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.40)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jkz0tZ3jdKge"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import BoxAnnotator,Detections\n"
      ],
      "metadata": {
        "id": "CiJPDWeva_OC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"vehicle-counting.mp4\"\n",
        "TARGET_VIDEO_PATH = f\"vehicle-counting-result.mp4\""
      ],
      "metadata": {
        "id": "gzIdnvsobNT0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTdzZ7nMdP8f"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"yolov8x.pt\""
      ],
      "metadata": {
        "id": "UhAv3KkBdIz5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ],
      "metadata": {
        "id": "pcQXp6eQdH79",
        "outputId": "b96afd8d-f780-43cc-c514-6ba86c7f2b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68,200,608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "DEwNRwYVgYe6",
        "outputId": "33bcd78c-a5a0-4183-c8a6-e6b56cc7172c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES_DICT = model.model.names"
      ],
      "metadata": {
        "id": "__kzXGEmdifS"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNNRPtRRarkP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAFba4GkombF"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "⚠️ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **23.01.2023** with version **YOLOv8.0.17**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGckxTNGLKDh",
        "outputId": "07ae1603-5b05-4382-c88a-833d295c4f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.8/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install \"ultralytics<=8.3.40\"\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e1ilpTlovJz"
      },
      "source": [
        "## Install ByteTrack\n",
        "\n",
        "[ByteTrack](https://github.com/ifzhang/ByteTrack) is great tracker but a bit poorly packaged. We need to jump through some fire hoops to make it work in tandem with [YOLOv8](https://github.com/ultralytics/ultralytics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KdBkOflo2xY",
        "outputId": "e4e4d579-bab0-4724-dd02-3bf314f0a66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "rwg-lY49o7Sf"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kSHFj8uQ9qe"
      },
      "source": [
        "## Install Roboflow Supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60yX_PFQ9A2",
        "outputId": "7d10efa9-4fc9-4cf2-b277-27a6849ffc4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supervision.__version__: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "7YDohOpMTWH5"
      },
      "outputs": [],
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from  supervision.tools.line_counter import LineCounter,LineCounterAnnotator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPdB-v_hWxBy"
      },
      "source": [
        "## Tracking utils\n",
        "\n",
        "Unfortunately, we have to manually match the bounding boxes coming from our model with those created by the tracker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "SE0G6LvFAXlk"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_417m4g9XVd"
      },
      "source": [
        "## Load pre-trained YOLOv8 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6to6MgPmTnCu"
      },
      "source": [
        "## Predict and annotate single frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "yKuDnOIxsN6l"
      },
      "outputs": [],
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.float = float\n",
        "\n"
      ],
      "metadata": {
        "id": "uD5LOmZNjt1T"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.geometry.dataclasses import Point\n",
        "\n",
        "LINE_START=Point(50,1500)\n",
        "LINE_END=Point(3840-50,1500)"
      ],
      "metadata": {
        "id": "xvYwl0Ggnto0"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1fa0b60279694bd78fbf353422b6e0b0",
            "a50eac2ce92243cc808ec2bb58ee7610",
            "4b5e5870c0d2494e856fa740a1cbfac8",
            "05649366f1bd4b56890d8ee7416b982b",
            "ae45d3d64bad4dea9963c431db6a09d7",
            "bb2768a05a14486da840beb3c10dae63",
            "1c20ee57d5084e3085bb525fb4eb3bdf",
            "956d690cd7084a18ad4e6558dd62c931",
            "e2e8fe38e36d4e049be57a088a36de60",
            "90edc64bf11c44148b5ab63209db1020",
            "17e80f3aa79a4611b2b15769bd868c2d"
          ]
        },
        "id": "hZQsgCa0cFvH",
        "outputId": "b77431ee-d1b3-4082-8b64-6eb4b749e525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/538 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa0b60279694bd78fbf353422b6e0b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 cars, 1 truck, 88.3ms\n",
            "Speed: 5.8ms preprocess, 88.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 77.4ms\n",
            "Speed: 13.1ms preprocess, 77.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 66.2ms\n",
            "Speed: 4.5ms preprocess, 66.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 70.3ms\n",
            "Speed: 3.9ms preprocess, 70.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.7ms\n",
            "Speed: 3.7ms preprocess, 63.7ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 68.3ms\n",
            "Speed: 8.5ms preprocess, 68.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 67.2ms\n",
            "Speed: 3.6ms preprocess, 67.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 70.8ms\n",
            "Speed: 3.7ms preprocess, 70.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 72.6ms\n",
            "Speed: 16.1ms preprocess, 72.6ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 90.0ms\n",
            "Speed: 15.8ms preprocess, 90.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.6ms\n",
            "Speed: 6.2ms preprocess, 63.6ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 89.3ms\n",
            "Speed: 7.6ms preprocess, 89.3ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 63.1ms\n",
            "Speed: 3.7ms preprocess, 63.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.2ms\n",
            "Speed: 3.6ms preprocess, 63.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 truck, 65.6ms\n",
            "Speed: 3.6ms preprocess, 65.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.2ms\n",
            "Speed: 3.8ms preprocess, 63.2ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.2ms\n",
            "Speed: 3.6ms preprocess, 63.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.2ms\n",
            "Speed: 3.7ms preprocess, 63.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 63.1ms\n",
            "Speed: 3.7ms preprocess, 63.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.0ms\n",
            "Speed: 3.6ms preprocess, 58.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.1ms\n",
            "Speed: 3.7ms preprocess, 58.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.0ms\n",
            "Speed: 3.6ms preprocess, 58.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 58.1ms\n",
            "Speed: 3.7ms preprocess, 58.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 46.6ms\n",
            "Speed: 3.6ms preprocess, 46.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 46.6ms\n",
            "Speed: 3.6ms preprocess, 46.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.6ms\n",
            "Speed: 6.6ms preprocess, 46.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.9ms\n",
            "Speed: 3.6ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.5ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 truck, 41.0ms\n",
            "Speed: 3.8ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 traffic light, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.0ms\n",
            "Speed: 4.0ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.2ms\n",
            "Speed: 3.6ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 5.7ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 39.3ms\n",
            "Speed: 5.7ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 2 trucks, 41.5ms\n",
            "Speed: 3.8ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.3ms\n",
            "Speed: 3.6ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 42.6ms\n",
            "Speed: 3.6ms preprocess, 42.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 42.2ms\n",
            "Speed: 3.6ms preprocess, 42.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 43.0ms\n",
            "Speed: 3.7ms preprocess, 43.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 2 trucks, 43.8ms\n",
            "Speed: 3.8ms preprocess, 43.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 45.3ms\n",
            "Speed: 5.8ms preprocess, 45.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 45.4ms\n",
            "Speed: 3.6ms preprocess, 45.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 40.5ms\n",
            "Speed: 3.6ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 40.2ms\n",
            "Speed: 3.8ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 2 trucks, 39.8ms\n",
            "Speed: 3.5ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.4ms\n",
            "Speed: 5.6ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.9ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 6.2ms preprocess, 39.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.9ms preprocess, 39.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.4ms\n",
            "Speed: 4.1ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.5ms\n",
            "Speed: 3.8ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.8ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 3 trucks, 39.6ms\n",
            "Speed: 3.7ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 42.1ms\n",
            "Speed: 3.7ms preprocess, 42.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 46.0ms\n",
            "Speed: 3.6ms preprocess, 46.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 39.3ms\n",
            "Speed: 6.9ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 9.6ms preprocess, 39.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.3ms\n",
            "Speed: 4.2ms preprocess, 39.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 39.8ms\n",
            "Speed: 3.7ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 1 bench, 49.3ms\n",
            "Speed: 5.0ms preprocess, 49.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 1 bench, 54.8ms\n",
            "Speed: 3.7ms preprocess, 54.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 54.3ms\n",
            "Speed: 5.4ms preprocess, 54.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 56.3ms\n",
            "Speed: 10.3ms preprocess, 56.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 58.5ms\n",
            "Speed: 4.0ms preprocess, 58.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 2 trucks, 58.7ms\n",
            "Speed: 4.1ms preprocess, 58.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 1 refrigerator, 60.1ms\n",
            "Speed: 4.7ms preprocess, 60.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 60.5ms\n",
            "Speed: 3.7ms preprocess, 60.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 60.5ms\n",
            "Speed: 3.6ms preprocess, 60.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 3.9ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 3.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 3.9ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 53.8ms\n",
            "Speed: 3.8ms preprocess, 53.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.3ms\n",
            "Speed: 3.6ms preprocess, 50.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.2ms\n",
            "Speed: 3.6ms preprocess, 50.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 49.8ms\n",
            "Speed: 8.8ms preprocess, 49.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.2ms\n",
            "Speed: 3.6ms preprocess, 45.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.7ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.7ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 46.0ms\n",
            "Speed: 5.3ms preprocess, 46.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.2ms\n",
            "Speed: 3.7ms preprocess, 45.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.8ms preprocess, 45.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.7ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.1ms\n",
            "Speed: 3.7ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.5ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.4ms\n",
            "Speed: 3.5ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.4ms\n",
            "Speed: 5.3ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 3.7ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.7ms\n",
            "Speed: 3.7ms preprocess, 45.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.1ms\n",
            "Speed: 5.3ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.9ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.3ms\n",
            "Speed: 3.6ms preprocess, 45.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.8ms\n",
            "Speed: 3.7ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 3.7ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.9ms\n",
            "Speed: 3.8ms preprocess, 39.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.4ms\n",
            "Speed: 3.4ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.9ms\n",
            "Speed: 5.7ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.4ms\n",
            "Speed: 3.8ms preprocess, 41.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 3.6ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 3.8ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.8ms\n",
            "Speed: 5.2ms preprocess, 42.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.5ms\n",
            "Speed: 5.2ms preprocess, 43.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.9ms\n",
            "Speed: 3.9ms preprocess, 42.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.3ms\n",
            "Speed: 3.7ms preprocess, 44.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.7ms preprocess, 44.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.4ms\n",
            "Speed: 3.7ms preprocess, 43.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 3.6ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.4ms\n",
            "Speed: 4.4ms preprocess, 42.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.3ms\n",
            "Speed: 3.7ms preprocess, 42.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.3ms\n",
            "Speed: 3.7ms preprocess, 42.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.3ms\n",
            "Speed: 3.7ms preprocess, 42.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 3.9ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.1ms\n",
            "Speed: 4.0ms preprocess, 40.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.4ms\n",
            "Speed: 10.6ms preprocess, 45.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.5ms\n",
            "Speed: 5.2ms preprocess, 45.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 5.5ms preprocess, 40.0ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 5.7ms preprocess, 44.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.9ms\n",
            "Speed: 3.7ms preprocess, 45.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.3ms\n",
            "Speed: 3.6ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 51.8ms\n",
            "Speed: 3.4ms preprocess, 51.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 50.3ms\n",
            "Speed: 7.1ms preprocess, 50.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.0ms\n",
            "Speed: 7.7ms preprocess, 52.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 52.9ms\n",
            "Speed: 5.6ms preprocess, 52.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 62.2ms\n",
            "Speed: 4.0ms preprocess, 62.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.8ms\n",
            "Speed: 3.8ms preprocess, 55.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 56.8ms\n",
            "Speed: 3.6ms preprocess, 56.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 55.4ms\n",
            "Speed: 3.7ms preprocess, 55.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.0ms\n",
            "Speed: 4.0ms preprocess, 48.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.9ms\n",
            "Speed: 4.2ms preprocess, 47.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.6ms\n",
            "Speed: 3.7ms preprocess, 47.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.7ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.7ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.5ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.7ms preprocess, 44.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.8ms preprocess, 44.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.6ms preprocess, 44.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.9ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.5ms\n",
            "Speed: 3.7ms preprocess, 42.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 3.6ms preprocess, 41.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 3.8ms preprocess, 41.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.6ms\n",
            "Speed: 3.7ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 4.2ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.6ms\n",
            "Speed: 5.0ms preprocess, 41.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.9ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 4.1ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.3ms\n",
            "Speed: 3.6ms preprocess, 41.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.9ms\n",
            "Speed: 3.8ms preprocess, 40.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.7ms\n",
            "Speed: 3.8ms preprocess, 42.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.8ms\n",
            "Speed: 3.7ms preprocess, 41.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.5ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 4.0ms preprocess, 40.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 4.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 4.1ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.1ms\n",
            "Speed: 3.6ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.7ms preprocess, 44.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.8ms\n",
            "Speed: 3.5ms preprocess, 45.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 45.9ms\n",
            "Speed: 3.8ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 42.0ms\n",
            "Speed: 4.0ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 3.8ms preprocess, 41.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 4.3ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.0ms\n",
            "Speed: 5.9ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.4ms\n",
            "Speed: 3.7ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.7ms\n",
            "Speed: 3.8ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 41.9ms\n",
            "Speed: 3.7ms preprocess, 41.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 2 trucks, 43.7ms\n",
            "Speed: 3.6ms preprocess, 43.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.6ms preprocess, 44.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.7ms\n",
            "Speed: 3.6ms preprocess, 44.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.4ms\n",
            "Speed: 3.5ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 3.7ms preprocess, 40.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.2ms\n",
            "Speed: 3.7ms preprocess, 40.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 48.5ms\n",
            "Speed: 6.0ms preprocess, 48.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 47.4ms\n",
            "Speed: 3.6ms preprocess, 47.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 43.5ms\n",
            "Speed: 3.5ms preprocess, 43.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.7ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 46.8ms\n",
            "Speed: 9.0ms preprocess, 46.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 64.3ms\n",
            "Speed: 8.0ms preprocess, 64.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 55.8ms\n",
            "Speed: 3.8ms preprocess, 55.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 57.8ms\n",
            "Speed: 4.4ms preprocess, 57.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 58.1ms\n",
            "Speed: 3.9ms preprocess, 58.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 63.8ms\n",
            "Speed: 4.3ms preprocess, 63.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 60.5ms\n",
            "Speed: 8.9ms preprocess, 60.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 61.8ms\n",
            "Speed: 3.7ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 61.8ms\n",
            "Speed: 3.9ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 61.8ms\n",
            "Speed: 3.6ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 1 traffic light, 47.2ms\n",
            "Speed: 3.7ms preprocess, 47.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 3 trucks, 47.3ms\n",
            "Speed: 3.6ms preprocess, 47.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.2ms\n",
            "Speed: 3.8ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 trucks, 47.2ms\n",
            "Speed: 3.7ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 47.2ms\n",
            "Speed: 3.8ms preprocess, 47.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 47.3ms\n",
            "Speed: 3.8ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 47.3ms\n",
            "Speed: 3.7ms preprocess, 47.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 41.2ms\n",
            "Speed: 3.6ms preprocess, 41.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 40.9ms\n",
            "Speed: 3.6ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 41.0ms\n",
            "Speed: 4.1ms preprocess, 41.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.9ms preprocess, 41.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 4.8ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.5ms preprocess, 41.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.9ms\n",
            "Speed: 3.8ms preprocess, 40.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.6ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.8ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.7ms preprocess, 41.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 3.8ms preprocess, 41.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.8ms\n",
            "Speed: 3.6ms preprocess, 45.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.9ms\n",
            "Speed: 3.7ms preprocess, 45.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.6ms\n",
            "Speed: 3.7ms preprocess, 40.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.4ms\n",
            "Speed: 3.6ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.5ms\n",
            "Speed: 3.7ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 4.0ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 4.3ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.4ms\n",
            "Speed: 6.3ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.5ms\n",
            "Speed: 3.7ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.3ms\n",
            "Speed: 3.5ms preprocess, 42.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.3ms\n",
            "Speed: 3.6ms preprocess, 41.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.6ms\n",
            "Speed: 3.7ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.4ms\n",
            "Speed: 3.6ms preprocess, 39.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.3ms\n",
            "Speed: 3.6ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 4.1ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.4ms\n",
            "Speed: 3.8ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.2ms\n",
            "Speed: 3.6ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 41.7ms\n",
            "Speed: 3.6ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 41.2ms\n",
            "Speed: 5.3ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.6ms\n",
            "Speed: 3.6ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 5.7ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.1ms\n",
            "Speed: 3.6ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 3.9ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 3.8ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 3.9ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.0ms\n",
            "Speed: 3.7ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 7.6ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.3ms\n",
            "Speed: 6.6ms preprocess, 43.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.7ms\n",
            "Speed: 8.5ms preprocess, 44.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.1ms\n",
            "Speed: 3.6ms preprocess, 48.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.3ms\n",
            "Speed: 7.4ms preprocess, 47.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 48.5ms\n",
            "Speed: 3.8ms preprocess, 48.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 57.1ms\n",
            "Speed: 3.6ms preprocess, 57.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.9ms\n",
            "Speed: 12.6ms preprocess, 51.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 52.0ms\n",
            "Speed: 5.0ms preprocess, 52.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.7ms\n",
            "Speed: 3.7ms preprocess, 52.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.1ms\n",
            "Speed: 5.6ms preprocess, 51.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.1ms\n",
            "Speed: 4.0ms preprocess, 51.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.1ms\n",
            "Speed: 4.5ms preprocess, 51.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.1ms\n",
            "Speed: 17.6ms preprocess, 51.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.2ms\n",
            "Speed: 3.6ms preprocess, 51.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.1ms\n",
            "Speed: 3.6ms preprocess, 51.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 51.1ms\n",
            "Speed: 3.6ms preprocess, 51.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 51.0ms\n",
            "Speed: 3.8ms preprocess, 51.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 43.5ms\n",
            "Speed: 3.6ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.9ms\n",
            "Speed: 3.8ms preprocess, 42.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.9ms\n",
            "Speed: 5.4ms preprocess, 42.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.9ms\n",
            "Speed: 3.8ms preprocess, 42.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.9ms\n",
            "Speed: 5.0ms preprocess, 42.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 42.9ms\n",
            "Speed: 3.9ms preprocess, 42.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.9ms\n",
            "Speed: 3.8ms preprocess, 42.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.9ms\n",
            "Speed: 3.6ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.7ms\n",
            "Speed: 5.6ms preprocess, 40.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 3.6ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 4.8ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.5ms\n",
            "Speed: 4.6ms preprocess, 42.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 4.3ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 5.9ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.7ms\n",
            "Speed: 3.6ms preprocess, 44.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 truck, 45.5ms\n",
            "Speed: 3.7ms preprocess, 45.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 45.9ms\n",
            "Speed: 3.9ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.6ms\n",
            "Speed: 3.6ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.8ms\n",
            "Speed: 5.9ms preprocess, 40.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.3ms\n",
            "Speed: 3.9ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.9ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.9ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 3.8ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.9ms\n",
            "Speed: 3.6ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.2ms\n",
            "Speed: 3.6ms preprocess, 46.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.2ms\n",
            "Speed: 4.8ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.6ms\n",
            "Speed: 3.7ms preprocess, 46.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.0ms\n",
            "Speed: 3.6ms preprocess, 48.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.9ms\n",
            "Speed: 3.6ms preprocess, 47.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.6ms\n",
            "Speed: 3.4ms preprocess, 44.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.9ms\n",
            "Speed: 6.7ms preprocess, 45.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.7ms\n",
            "Speed: 3.6ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.2ms\n",
            "Speed: 3.6ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.3ms\n",
            "Speed: 3.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.9ms\n",
            "Speed: 3.6ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 4.2ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.8ms preprocess, 39.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.2ms\n",
            "Speed: 3.6ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 3.5ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 40.1ms\n",
            "Speed: 3.7ms preprocess, 40.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 39.3ms\n",
            "Speed: 6.6ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.1ms\n",
            "Speed: 3.6ms preprocess, 43.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.0ms\n",
            "Speed: 13.8ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.3ms\n",
            "Speed: 3.6ms preprocess, 47.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.9ms\n",
            "Speed: 6.0ms preprocess, 52.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.0ms\n",
            "Speed: 3.6ms preprocess, 52.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.2ms\n",
            "Speed: 4.2ms preprocess, 52.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 52.9ms\n",
            "Speed: 3.5ms preprocess, 52.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 55.0ms\n",
            "Speed: 3.5ms preprocess, 55.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 54.8ms\n",
            "Speed: 3.6ms preprocess, 54.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 60.8ms\n",
            "Speed: 3.6ms preprocess, 60.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 63.6ms\n",
            "Speed: 3.5ms preprocess, 63.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 58.0ms\n",
            "Speed: 3.5ms preprocess, 58.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 59.2ms\n",
            "Speed: 3.6ms preprocess, 59.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 59.3ms\n",
            "Speed: 3.5ms preprocess, 59.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 59.2ms\n",
            "Speed: 3.7ms preprocess, 59.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.7ms\n",
            "Speed: 3.7ms preprocess, 48.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 1 traffic light, 48.7ms\n",
            "Speed: 3.6ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.8ms\n",
            "Speed: 3.6ms preprocess, 48.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.7ms\n",
            "Speed: 4.9ms preprocess, 48.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.9ms\n",
            "Speed: 3.7ms preprocess, 41.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 4.1ms preprocess, 41.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 6.2ms preprocess, 41.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 4.0ms preprocess, 41.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 4.4ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.8ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 4.9ms preprocess, 41.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 7.7ms preprocess, 41.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.4ms\n",
            "Speed: 3.8ms preprocess, 41.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 43.4ms\n",
            "Speed: 3.6ms preprocess, 43.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.9ms\n",
            "Speed: 3.8ms preprocess, 42.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 42.6ms\n",
            "Speed: 3.7ms preprocess, 42.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.2ms\n",
            "Speed: 3.6ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.3ms\n",
            "Speed: 4.1ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.3ms\n",
            "Speed: 4.1ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 45.3ms\n",
            "Speed: 3.6ms preprocess, 45.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.6ms\n",
            "Speed: 3.7ms preprocess, 46.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 46.9ms\n",
            "Speed: 3.8ms preprocess, 46.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.3ms\n",
            "Speed: 3.9ms preprocess, 47.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 47.3ms\n",
            "Speed: 3.6ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.7ms\n",
            "Speed: 3.6ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.7ms\n",
            "Speed: 3.5ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 48.7ms\n",
            "Speed: 3.8ms preprocess, 48.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 49.5ms\n",
            "Speed: 3.7ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.2ms\n",
            "Speed: 3.8ms preprocess, 50.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 50.1ms\n",
            "Speed: 3.5ms preprocess, 50.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.8ms preprocess, 44.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.2ms\n",
            "Speed: 3.9ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 4.1ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 4.1ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 3.6ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 44.1ms\n",
            "Speed: 3.7ms preprocess, 44.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 44.1ms\n",
            "Speed: 10.0ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 47.6ms\n",
            "Speed: 3.5ms preprocess, 47.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 51.1ms\n",
            "Speed: 3.6ms preprocess, 51.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 51.1ms\n",
            "Speed: 3.7ms preprocess, 51.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.0ms\n",
            "Speed: 3.8ms preprocess, 52.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 52.0ms\n",
            "Speed: 4.2ms preprocess, 52.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.7ms\n",
            "Speed: 3.6ms preprocess, 41.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.7ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.4ms\n",
            "Speed: 3.5ms preprocess, 41.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.4ms\n",
            "Speed: 3.6ms preprocess, 41.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.8ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.7ms preprocess, 41.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 41.5ms\n",
            "Speed: 3.6ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 5.9ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.4ms\n",
            "Speed: 3.6ms preprocess, 41.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 41.5ms\n",
            "Speed: 3.5ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.3ms\n",
            "Speed: 3.7ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.4ms\n",
            "Speed: 3.6ms preprocess, 42.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 46.9ms\n",
            "Speed: 5.2ms preprocess, 46.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 3.7ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 refrigerator, 47.5ms\n",
            "Speed: 3.6ms preprocess, 47.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 5.7ms preprocess, 40.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 43.4ms\n",
            "Speed: 3.6ms preprocess, 43.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 42.1ms\n",
            "Speed: 5.5ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 8.3ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 40.0ms\n",
            "Speed: 7.5ms preprocess, 40.0ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 53.8ms\n",
            "Speed: 4.9ms preprocess, 53.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 58.8ms\n",
            "Speed: 3.6ms preprocess, 58.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 55.8ms\n",
            "Speed: 3.7ms preprocess, 55.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 58.1ms\n",
            "Speed: 4.8ms preprocess, 58.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 59.2ms\n",
            "Speed: 5.1ms preprocess, 59.2ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 60.5ms\n",
            "Speed: 3.6ms preprocess, 60.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 61.8ms\n",
            "Speed: 3.6ms preprocess, 61.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 58.4ms\n",
            "Speed: 3.9ms preprocess, 58.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 54.8ms\n",
            "Speed: 3.7ms preprocess, 54.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 52.9ms\n",
            "Speed: 3.6ms preprocess, 52.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 52.9ms\n",
            "Speed: 3.6ms preprocess, 52.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 52.9ms\n",
            "Speed: 3.6ms preprocess, 52.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 52.8ms\n",
            "Speed: 3.6ms preprocess, 52.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 49.5ms\n",
            "Speed: 3.6ms preprocess, 49.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 49.5ms\n",
            "Speed: 3.5ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 49.5ms\n",
            "Speed: 5.6ms preprocess, 49.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 49.5ms\n",
            "Speed: 3.6ms preprocess, 49.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 49.7ms\n",
            "Speed: 3.5ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 49.5ms\n",
            "Speed: 4.5ms preprocess, 49.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 49.4ms\n",
            "Speed: 2.8ms preprocess, 49.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 49.4ms\n",
            "Speed: 3.1ms preprocess, 49.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 49.4ms\n",
            "Speed: 3.0ms preprocess, 49.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "line_counter = LineCounter(start=LINE_START,end=LINE_END)\n",
        "line_annotator=LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator,total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id=match_detections_with_tracks(detections=detections,tracks=tracks)\n",
        "        # format custom labels\n",
        "        detections.tracker_id=np.array(tracker_id)\n",
        "        line_counter.update(detections=detections)\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "\n",
        "        # updating line counter\n",
        "\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame,line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZbGmYfiT0EV"
      },
      "source": [
        "## Predict and annotate whole video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjP8Pn10XuJm"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/vehicle-counting-result.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btq7JavXknU",
        "outputId": "40a438f1-f142-455e-ed17-be2b82599485"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VideoInfo(width=3840, height=2160, fps=25, total_frames=538)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9ppb7bFvWfc"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# create LineCounter instance\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "        # model prediction on single frame and conversion to supervision Detections\n",
        "        results = model(frame)\n",
        "        detections = Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "        # filtering out detections with unwanted classes\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # tracking detections\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "        # filtering out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.filter(mask=mask, inplace=True)\n",
        "        # format custom labels\n",
        "        labels = [\n",
        "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for _, confidence, class_id, tracker_id\n",
        "            in detections\n",
        "        ]\n",
        "        # updating line counter\n",
        "        line_counter.update(detections=detections)\n",
        "        # annotate and display frame\n",
        "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "        sink.write_frame(frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiFSEV9RIC-"
      },
      "source": [
        "## 🏆 Congratulations\n",
        "\n",
        "### Learning Resources\n",
        "\n",
        "Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n",
        "\n",
        "- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n",
        "- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n",
        "- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n",
        "- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n",
        "\n",
        "### Convert data formats\n",
        "\n",
        "Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n",
        "\n",
        "### Connect computer vision to your project logic\n",
        "\n",
        "[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fa0b60279694bd78fbf353422b6e0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a50eac2ce92243cc808ec2bb58ee7610",
              "IPY_MODEL_4b5e5870c0d2494e856fa740a1cbfac8",
              "IPY_MODEL_05649366f1bd4b56890d8ee7416b982b"
            ],
            "layout": "IPY_MODEL_ae45d3d64bad4dea9963c431db6a09d7"
          }
        },
        "a50eac2ce92243cc808ec2bb58ee7610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2768a05a14486da840beb3c10dae63",
            "placeholder": "​",
            "style": "IPY_MODEL_1c20ee57d5084e3085bb525fb4eb3bdf",
            "value": "100%"
          }
        },
        "4b5e5870c0d2494e856fa740a1cbfac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956d690cd7084a18ad4e6558dd62c931",
            "max": 538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e8fe38e36d4e049be57a088a36de60",
            "value": 538
          }
        },
        "05649366f1bd4b56890d8ee7416b982b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90edc64bf11c44148b5ab63209db1020",
            "placeholder": "​",
            "style": "IPY_MODEL_17e80f3aa79a4611b2b15769bd868c2d",
            "value": " 538/538 [01:23&lt;00:00,  7.14it/s]"
          }
        },
        "ae45d3d64bad4dea9963c431db6a09d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2768a05a14486da840beb3c10dae63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c20ee57d5084e3085bb525fb4eb3bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "956d690cd7084a18ad4e6558dd62c931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e8fe38e36d4e049be57a088a36de60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90edc64bf11c44148b5ab63209db1020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e80f3aa79a4611b2b15769bd868c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}